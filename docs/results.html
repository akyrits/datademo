<div class="section-card" id="results">

  <h2>Results</h2>
  <p>
    Model performance was evaluated across multiple training configurations using a W&B sweep.
    Performance metrics consistently show that pretrained AlexNet with RGB input, Adam optimizer,
    and GPU acceleration delivers the strongest generalization.
  </p>

  <!-- ================================
       METRIC SUMMARY BOX
  ================================= -->
  <div class="metric-box">
    <h3>Performance Summary (Best Model)</h3>
    <ul>
      <li><strong>Best Training Accuracy:</strong> 0.99</li>
      <li><strong>Best Validation Accuracy:</strong> 0.95</li>
      <li><strong>Validation Loss (best epoch):</strong> ~0.17–0.22</li>
      <li><strong>Best Epoch:</strong> ~8–10</li>
      <li><strong>Best Configuration:</strong> AlexNet (pretrained) + RGB + Adam (lr=1e-4) + Batch 32 + GPU</li>
    </ul>
  </div>

  <!-- ================================
       ACADEMIC RESULTS TABLE
  ================================= -->
  <h3>Comparison of Training Configurations</h3>
  <p>The table below summarizes validation accuracy across key hyperparameters tested.</p>

  <table>
    <thead>
      <tr>
        <th>Configuration</th>
        <th>Details</th>
        <th>Best Validation Accuracy</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>RGB + GPU + Adam</strong></td>
        <td>Pretrained AlexNet, lr=1e-4, batch=32</td>
        <td><strong>0.95</strong></td>
      </tr>
      <tr>
        <td>RGB + CPU + Adam</td>
        <td>Same settings as GPU run</td>
        <td>~0.92</td>
      </tr>
      <tr>
        <td>Grayscale + GPU</td>
        <td>Image converted to grayscale before training</td>
        <td>~0.88</td>
      </tr>
      <tr>
        <td>Optimizer: SGD</td>
        <td>lr=1e-3, batch=32</td>
        <td>~0.90</td>
      </tr>
      <tr>
        <td>Grayscale + CPU</td>
        <td>Baseline grayscale configuration</td>
        <td>~0.86</td>
      </tr>
    </tbody>
  </table>

  <!-- ================================
       VISUALIZATIONS (Your Images)
  ================================= -->
  <h3>Visualizations</h3>

  <h4>Training vs Validation Accuracy</h4>
  <figure>
    <img src="assets/train_acc.png" alt="Training accuracy across runs">
    <figcaption>
      GPU + RGB reaches the highest accuracy and maintains stronger stability compared to grayscale or CPU runs.
    </figcaption>
  </figure>

  <h4>Validation Accuracy Progression</h4>
  <figure>
    <img src="assets/val_acc.png" alt="Validation accuracy across epochs">
    <figcaption>
      Validation accuracy peaks around 0.94–0.95 for the best configuration, while grayscale and SGD runs 
      fluctuate more and achieve lower overall accuracy.
    </figcaption>
  </figure>

  <h4>Validation Loss</h4>
  <figure>
    <img src="assets/val_loss.png" alt="Validation loss across epochs">
    <figcaption>
      Strong configurations stabilize at low validation loss (~0.17–0.22). Weaker ones (e.g., grayscale + SGD) 
      show higher and more volatile loss curves, indicating poorer generalization.
    </figcaption>
  </figure>

  <h4>Best Validation Accuracy per Configuration</h4>
  <figure>
    <img src="assets/best_val_acc.png" alt="Best validation accuracy by hyperparameter group">
    <figcaption>
      RGB + GPU + Adam is the clear top performer, achieving ~0.95 validation accuracy. 
      Grayscale inputs consistently reduce model performance.
    </figcaption>
  </figure>

  <!-- ================================
       INTERPRETATION
  ================================= -->
  <h3>Interpretation</h3>

  <p>
    The best-performing model excels because RGB images retain richer visual cues related to 
    dog emotional state — eye shape, ear tension, muzzle wrinkles, and color contrast — which 
    grayscale transformations diminish.
  </p>

  <p>
    GPU acceleration not only trains faster but also improves stability in validation curves, 
    likely due to more consistent batch-normalization behavior and reduced numerical noise 
    across iterations.
  </p>

  <p>
    Models trained with SGD showed slower convergence and higher variance in validation metrics, 
    whereas Adam consistently produced smoother and more optimal trajectories.
  </p>

  <!-- ================================
       OVERALL TAKEAWAYS
  ================================= -->
  <h3>Overall Takeaways</h3>
  <ul>
    <li>Transfer learning with AlexNet is highly effective for dog emotion classification.</li>
    <li>Color (RGB) is essential — grayscale reduces accuracy by ~7–10%.</li>
    <li>Adam optimizer provides the strongest generalization and fastest convergence.</li>
    <li>GPU training produces more stable validation behavior and better peak accuracy.</li>
    <li>The model generalizes well, achieving ~0.95 validation accuracy on a modest dataset.</li>
    <li>Future extensions include multi-class emotion labeling and video-based temporal modeling.</li>
  </ul>

</div>
